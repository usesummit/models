#!/usesummit/sel/0.1a
# [ GPT // Call GPT using a prompt object. ]


# This provides GPT with the context it needs to run.  Notice the search results are injected into the prompt using {{ liquid_syntax }}.
"prompt": =Object({"cache_duration": 600, "prompts": [{"role": "user", "content": "Why do people love Austin, TX?  Be concise, this needs to fit into a couple of tweets."<prompt>}]})

# Calls GPT with the enriched prompt passed in.
"gpt": =Ai("gpt-4o"<model>, "{{ OPENAI_KEY }}")

# Response is the data that will appear in the response to this model being called over API.
"gpt_response": =Response("gpt_response")

"prompt" -> "gpt"
"gpt" -> "gpt_response"